{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47b34975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the system\n",
    "\n",
    "from grader.models.assignment import Assignment\n",
    "from grader.models.teacher import Teacher\n",
    "from grader.models.student import Student\n",
    "\n",
    "assignement = Assignment(\"Math Assignment 1\")\n",
    "teacher = Teacher(assignement.grader)\n",
    "student = Student(\"Yasith\", assignement.grader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "663b32fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case for circle_area function\n",
    "\n",
    "import math\n",
    "from grader.models.test_case import TestCase\n",
    "\n",
    "\n",
    "test_case_name = \"circle_area_test_case\"\n",
    "\n",
    "def test_circle_area(submission):\n",
    "    \"\"\"\n",
    "    Test if the student correctly implemented circle_area function\n",
    "    \"\"\"\n",
    "    # Check if function exists\n",
    "    if test_case_name not in submission:\n",
    "        return {\"score\": 0, \"feedback\": f\"❌ Function {test_case_name} not found!\"}\n",
    "    \n",
    "    func = submission[test_case_name]\n",
    "    \n",
    "    # Test with multiple inputs\n",
    "    test_cases = [\n",
    "        (1, math.pi),           # radius=1, expected=π\n",
    "        (3, 9 * math.pi),       # radius=3, expected=9π\n",
    "        (0, 0),                 # radius=0, expected=0\n",
    "        (5.5, 30.25 * math.pi)  # radius=5.5, expected=30.25π\n",
    "    ]\n",
    "    \n",
    "    score = 0\n",
    "    feedback_parts = []\n",
    "    \n",
    "    for radius, expected in test_cases:\n",
    "        try:\n",
    "            result = func(radius)\n",
    "            if abs(result - expected) < 0.001:  # Allow small floating point errors\n",
    "                score += 1\n",
    "                feedback_parts.append(f\"✅ Correct for radius={radius}\")\n",
    "            else:\n",
    "                feedback_parts.append(f\"❌ Wrong for radius={radius}: got {result}, expected {expected:.3f}\")\n",
    "        except Exception as e:\n",
    "            feedback_parts.append(f\"❌ Error for radius={radius}: {str(e)}\")\n",
    "    \n",
    "    final_score = score / len(test_cases)\n",
    "    feedback = f\"Circle Area Test: {score}/{len(test_cases)} test cases passed\\n\" + \"\\n\".join(feedback_parts)\n",
    "    \n",
    "    return {\"score\": final_score, \"feedback\": feedback}\n",
    "\n",
    "test_case = TestCase(\n",
    "    name=test_case_name,\n",
    "    test_function=test_circle_area,\n",
    "    points=5,\n",
    "    description=\"Tests the circle_area function with various radius.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68d1623c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added test case 'circle_area_test_case' (5 points)\n"
     ]
    }
   ],
   "source": [
    "# Add the test case to the teacher's grader\n",
    "teacher.add_test_case(test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff393e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a submission\n",
    "from grader.models.submission import Submission\n",
    "\n",
    "def circle_area_by_student(radius):\n",
    "    return math.pi * radius * radius\n",
    "\n",
    "submission = Submission()\n",
    "\n",
    "submission.add_submission_item(\"circle_area_test_case\", circle_area_by_student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f2acf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit answer by student\n",
    "result = student.submit_assignment(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9a2619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 5.0/5 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Score:\", f\"{result['total_score']}/{result['max_score']} ({result['percentage']:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b8b0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
